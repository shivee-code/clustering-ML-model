{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd101c91-a463-4982-8032-111093f7e628",
   "metadata": {},
   "source": [
    "# ***K-Means Algorithm***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83b9f8a4-822c-477f-9f0c-a0f49a5963e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libs\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c10f77e-a688-4ebb-9d2e-41c021dab74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Region</th>\n",
       "      <th>Fresh</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Grocery</th>\n",
       "      <th>Frozen</th>\n",
       "      <th>Detergents_Paper</th>\n",
       "      <th>Delicassen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12669</td>\n",
       "      <td>9656</td>\n",
       "      <td>7561</td>\n",
       "      <td>214</td>\n",
       "      <td>2674</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7057</td>\n",
       "      <td>9810</td>\n",
       "      <td>9568</td>\n",
       "      <td>1762</td>\n",
       "      <td>3293</td>\n",
       "      <td>1776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6353</td>\n",
       "      <td>8808</td>\n",
       "      <td>7684</td>\n",
       "      <td>2405</td>\n",
       "      <td>3516</td>\n",
       "      <td>7844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13265</td>\n",
       "      <td>1196</td>\n",
       "      <td>4221</td>\n",
       "      <td>6404</td>\n",
       "      <td>507</td>\n",
       "      <td>1788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>22615</td>\n",
       "      <td>5410</td>\n",
       "      <td>7198</td>\n",
       "      <td>3915</td>\n",
       "      <td>1777</td>\n",
       "      <td>5185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Channel  Region  Fresh  Milk  Grocery  Frozen  Detergents_Paper  Delicassen\n",
       "0        2       3  12669  9656     7561     214              2674        1338\n",
       "1        2       3   7057  9810     9568    1762              3293        1776\n",
       "2        2       3   6353  8808     7684    2405              3516        7844\n",
       "3        1       3  13265  1196     4221    6404               507        1788\n",
       "4        2       3  22615  5410     7198    3915              1777        5185"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Wholesale data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fc52917-9bd5-4cca-a8fa-47a5369f15ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Region</th>\n",
       "      <th>Fresh</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Grocery</th>\n",
       "      <th>Frozen</th>\n",
       "      <th>Detergents_Paper</th>\n",
       "      <th>Delicassen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>440.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.322727</td>\n",
       "      <td>2.543182</td>\n",
       "      <td>12000.297727</td>\n",
       "      <td>5796.265909</td>\n",
       "      <td>7951.277273</td>\n",
       "      <td>3071.931818</td>\n",
       "      <td>2881.493182</td>\n",
       "      <td>1524.870455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.468052</td>\n",
       "      <td>0.774272</td>\n",
       "      <td>12647.328865</td>\n",
       "      <td>7380.377175</td>\n",
       "      <td>9503.162829</td>\n",
       "      <td>4854.673333</td>\n",
       "      <td>4767.854448</td>\n",
       "      <td>2820.105937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3127.750000</td>\n",
       "      <td>1533.000000</td>\n",
       "      <td>2153.000000</td>\n",
       "      <td>742.250000</td>\n",
       "      <td>256.750000</td>\n",
       "      <td>408.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8504.000000</td>\n",
       "      <td>3627.000000</td>\n",
       "      <td>4755.500000</td>\n",
       "      <td>1526.000000</td>\n",
       "      <td>816.500000</td>\n",
       "      <td>965.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>16933.750000</td>\n",
       "      <td>7190.250000</td>\n",
       "      <td>10655.750000</td>\n",
       "      <td>3554.250000</td>\n",
       "      <td>3922.000000</td>\n",
       "      <td>1820.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>112151.000000</td>\n",
       "      <td>73498.000000</td>\n",
       "      <td>92780.000000</td>\n",
       "      <td>60869.000000</td>\n",
       "      <td>40827.000000</td>\n",
       "      <td>47943.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Channel      Region          Fresh          Milk       Grocery  \\\n",
       "count  440.000000  440.000000     440.000000    440.000000    440.000000   \n",
       "mean     1.322727    2.543182   12000.297727   5796.265909   7951.277273   \n",
       "std      0.468052    0.774272   12647.328865   7380.377175   9503.162829   \n",
       "min      1.000000    1.000000       3.000000     55.000000      3.000000   \n",
       "25%      1.000000    2.000000    3127.750000   1533.000000   2153.000000   \n",
       "50%      1.000000    3.000000    8504.000000   3627.000000   4755.500000   \n",
       "75%      2.000000    3.000000   16933.750000   7190.250000  10655.750000   \n",
       "max      2.000000    3.000000  112151.000000  73498.000000  92780.000000   \n",
       "\n",
       "             Frozen  Detergents_Paper    Delicassen  \n",
       "count    440.000000        440.000000    440.000000  \n",
       "mean    3071.931818       2881.493182   1524.870455  \n",
       "std     4854.673333       4767.854448   2820.105937  \n",
       "min       25.000000          3.000000      3.000000  \n",
       "25%      742.250000        256.750000    408.250000  \n",
       "50%     1526.000000        816.500000    965.500000  \n",
       "75%     3554.250000       3922.000000   1820.250000  \n",
       "max    60869.000000      40827.000000  47943.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stats of the data \n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87257423-ed24-4857-8947-e1f085e68ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.400000e+02</td>\n",
       "      <td>4.400000e+02</td>\n",
       "      <td>4.400000e+02</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>4.400000e+02</td>\n",
       "      <td>4.400000e+02</td>\n",
       "      <td>4.400000e+02</td>\n",
       "      <td>4.400000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.614870e-17</td>\n",
       "      <td>3.552714e-16</td>\n",
       "      <td>-3.431598e-17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.037175e-17</td>\n",
       "      <td>3.633457e-17</td>\n",
       "      <td>2.422305e-17</td>\n",
       "      <td>-8.074349e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.001138e+00</td>\n",
       "      <td>1.001138e+00</td>\n",
       "      <td>1.001138e+00</td>\n",
       "      <td>1.001138</td>\n",
       "      <td>1.001138e+00</td>\n",
       "      <td>1.001138e+00</td>\n",
       "      <td>1.001138e+00</td>\n",
       "      <td>1.001138e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-6.902971e-01</td>\n",
       "      <td>-1.995342e+00</td>\n",
       "      <td>-9.496831e-01</td>\n",
       "      <td>-0.778795</td>\n",
       "      <td>-8.373344e-01</td>\n",
       "      <td>-6.283430e-01</td>\n",
       "      <td>-6.044165e-01</td>\n",
       "      <td>-5.402644e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.902971e-01</td>\n",
       "      <td>-7.023369e-01</td>\n",
       "      <td>-7.023339e-01</td>\n",
       "      <td>-0.578306</td>\n",
       "      <td>-6.108364e-01</td>\n",
       "      <td>-4.804306e-01</td>\n",
       "      <td>-5.511349e-01</td>\n",
       "      <td>-3.964005e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-6.902971e-01</td>\n",
       "      <td>5.906683e-01</td>\n",
       "      <td>-2.767602e-01</td>\n",
       "      <td>-0.294258</td>\n",
       "      <td>-3.366684e-01</td>\n",
       "      <td>-3.188045e-01</td>\n",
       "      <td>-4.336004e-01</td>\n",
       "      <td>-1.985766e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.448652e+00</td>\n",
       "      <td>5.906683e-01</td>\n",
       "      <td>3.905226e-01</td>\n",
       "      <td>0.189092</td>\n",
       "      <td>2.849105e-01</td>\n",
       "      <td>9.946441e-02</td>\n",
       "      <td>2.184822e-01</td>\n",
       "      <td>1.048598e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.448652e+00</td>\n",
       "      <td>5.906683e-01</td>\n",
       "      <td>7.927738e+00</td>\n",
       "      <td>9.183650</td>\n",
       "      <td>8.936528e+00</td>\n",
       "      <td>1.191900e+01</td>\n",
       "      <td>7.967672e+00</td>\n",
       "      <td>1.647845e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2           3             4  \\\n",
       "count  4.400000e+02  4.400000e+02  4.400000e+02  440.000000  4.400000e+02   \n",
       "mean   1.614870e-17  3.552714e-16 -3.431598e-17    0.000000 -4.037175e-17   \n",
       "std    1.001138e+00  1.001138e+00  1.001138e+00    1.001138  1.001138e+00   \n",
       "min   -6.902971e-01 -1.995342e+00 -9.496831e-01   -0.778795 -8.373344e-01   \n",
       "25%   -6.902971e-01 -7.023369e-01 -7.023339e-01   -0.578306 -6.108364e-01   \n",
       "50%   -6.902971e-01  5.906683e-01 -2.767602e-01   -0.294258 -3.366684e-01   \n",
       "75%    1.448652e+00  5.906683e-01  3.905226e-01    0.189092  2.849105e-01   \n",
       "max    1.448652e+00  5.906683e-01  7.927738e+00    9.183650  8.936528e+00   \n",
       "\n",
       "                  5             6             7  \n",
       "count  4.400000e+02  4.400000e+02  4.400000e+02  \n",
       "mean   3.633457e-17  2.422305e-17 -8.074349e-18  \n",
       "std    1.001138e+00  1.001138e+00  1.001138e+00  \n",
       "min   -6.283430e-01 -6.044165e-01 -5.402644e-01  \n",
       "25%   -4.804306e-01 -5.511349e-01 -3.964005e-01  \n",
       "50%   -3.188045e-01 -4.336004e-01 -1.985766e-01  \n",
       "75%    9.946441e-02  2.184822e-01  1.048598e-01  \n",
       "max    1.191900e+01  7.967672e+00  1.647845e+01  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardizing the data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "pd.DataFrame(data_scaled).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8416f819-a1a4-4fa9-9ec2-72523b84d342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KMeans in module sklearn.cluster._kmeans:\n",
      "\n",
      "class KMeans(_BaseKMeans)\n",
      " |  KMeans(n_clusters=8, *, init='k-means++', n_init='auto', max_iter=300, tol=0.0001, verbose=0, random_state=None, copy_x=True, algorithm='lloyd')\n",
      " |\n",
      " |  K-Means clustering.\n",
      " |\n",
      " |  Read more in the :ref:`User Guide <k_means>`.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |\n",
      " |  n_clusters : int, default=8\n",
      " |      The number of clusters to form as well as the number of\n",
      " |      centroids to generate.\n",
      " |\n",
      " |      For an example of how to choose an optimal value for `n_clusters` refer to\n",
      " |      :ref:`sphx_glr_auto_examples_cluster_plot_kmeans_silhouette_analysis.py`.\n",
      " |\n",
      " |  init : {'k-means++', 'random'}, callable or array-like of shape             (n_clusters, n_features), default='k-means++'\n",
      " |      Method for initialization:\n",
      " |\n",
      " |      * 'k-means++' : selects initial cluster centroids using sampling             based on an empirical probability distribution of the points'             contribution to the overall inertia. This technique speeds up             convergence. The algorithm implemented is \"greedy k-means++\". It             differs from the vanilla k-means++ by making several trials at             each sampling step and choosing the best centroid among them.\n",
      " |\n",
      " |      * 'random': choose `n_clusters` observations (rows) at random from         data for the initial centroids.\n",
      " |\n",
      " |      * If an array is passed, it should be of shape (n_clusters, n_features)        and gives the initial centers.\n",
      " |\n",
      " |      * If a callable is passed, it should take arguments X, n_clusters and a        random state and return an initialization.\n",
      " |\n",
      " |      For an example of how to use the different `init` strategy, see the example\n",
      " |      entitled :ref:`sphx_glr_auto_examples_cluster_plot_kmeans_digits.py`.\n",
      " |\n",
      " |  n_init : 'auto' or int, default='auto'\n",
      " |      Number of times the k-means algorithm is run with different centroid\n",
      " |      seeds. The final results is the best output of `n_init` consecutive runs\n",
      " |      in terms of inertia. Several runs are recommended for sparse\n",
      " |      high-dimensional problems (see :ref:`kmeans_sparse_high_dim`).\n",
      " |\n",
      " |      When `n_init='auto'`, the number of runs depends on the value of init:\n",
      " |      10 if using `init='random'` or `init` is a callable;\n",
      " |      1 if using `init='k-means++'` or `init` is an array-like.\n",
      " |\n",
      " |      .. versionadded:: 1.2\n",
      " |         Added 'auto' option for `n_init`.\n",
      " |\n",
      " |      .. versionchanged:: 1.4\n",
      " |         Default value for `n_init` changed to `'auto'`.\n",
      " |\n",
      " |  max_iter : int, default=300\n",
      " |      Maximum number of iterations of the k-means algorithm for a\n",
      " |      single run.\n",
      " |\n",
      " |  tol : float, default=1e-4\n",
      " |      Relative tolerance with regards to Frobenius norm of the difference\n",
      " |      in the cluster centers of two consecutive iterations to declare\n",
      " |      convergence.\n",
      " |\n",
      " |  verbose : int, default=0\n",
      " |      Verbosity mode.\n",
      " |\n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Determines random number generation for centroid initialization. Use\n",
      " |      an int to make the randomness deterministic.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |\n",
      " |  copy_x : bool, default=True\n",
      " |      When pre-computing distances it is more numerically accurate to center\n",
      " |      the data first. If copy_x is True (default), then the original data is\n",
      " |      not modified. If False, the original data is modified, and put back\n",
      " |      before the function returns, but small numerical differences may be\n",
      " |      introduced by subtracting and then adding the data mean. Note that if\n",
      " |      the original data is not C-contiguous, a copy will be made even if\n",
      " |      copy_x is False. If the original data is sparse, but not in CSR format,\n",
      " |      a copy will be made even if copy_x is False.\n",
      " |\n",
      " |  algorithm : {\"lloyd\", \"elkan\"}, default=\"lloyd\"\n",
      " |      K-means algorithm to use. The classical EM-style algorithm is `\"lloyd\"`.\n",
      " |      The `\"elkan\"` variation can be more efficient on some datasets with\n",
      " |      well-defined clusters, by using the triangle inequality. However it's\n",
      " |      more memory intensive due to the allocation of an extra array of shape\n",
      " |      `(n_samples, n_clusters)`.\n",
      " |\n",
      " |      .. versionchanged:: 0.18\n",
      " |          Added Elkan algorithm\n",
      " |\n",
      " |      .. versionchanged:: 1.1\n",
      " |          Renamed \"full\" to \"lloyd\", and deprecated \"auto\" and \"full\".\n",
      " |          Changed \"auto\" to use \"lloyd\" instead of \"elkan\".\n",
      " |\n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cluster_centers_ : ndarray of shape (n_clusters, n_features)\n",
      " |      Coordinates of cluster centers. If the algorithm stops before fully\n",
      " |      converging (see ``tol`` and ``max_iter``), these will not be\n",
      " |      consistent with ``labels_``.\n",
      " |\n",
      " |  labels_ : ndarray of shape (n_samples,)\n",
      " |      Labels of each point\n",
      " |\n",
      " |  inertia_ : float\n",
      " |      Sum of squared distances of samples to their closest cluster center,\n",
      " |      weighted by the sample weights if provided.\n",
      " |\n",
      " |  n_iter_ : int\n",
      " |      Number of iterations run.\n",
      " |\n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |\n",
      " |      .. versionadded:: 0.24\n",
      " |\n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |\n",
      " |      .. versionadded:: 1.0\n",
      " |\n",
      " |  See Also\n",
      " |  --------\n",
      " |  MiniBatchKMeans : Alternative online implementation that does incremental\n",
      " |      updates of the centers positions using mini-batches.\n",
      " |      For large scale learning (say n_samples > 10k) MiniBatchKMeans is\n",
      " |      probably much faster than the default batch implementation.\n",
      " |\n",
      " |  Notes\n",
      " |  -----\n",
      " |  The k-means problem is solved using either Lloyd's or Elkan's algorithm.\n",
      " |\n",
      " |  The average complexity is given by O(k n T), where n is the number of\n",
      " |  samples and T is the number of iteration.\n",
      " |\n",
      " |  The worst case complexity is given by O(n^(k+2/p)) with\n",
      " |  n = n_samples, p = n_features.\n",
      " |  Refer to :doi:`\"How slow is the k-means method?\" D. Arthur and S. Vassilvitskii -\n",
      " |  SoCG2006.<10.1145/1137856.1137880>` for more details.\n",
      " |\n",
      " |  In practice, the k-means algorithm is very fast (one of the fastest\n",
      " |  clustering algorithms available), but it falls in local minima. That's why\n",
      " |  it can be useful to restart it several times.\n",
      " |\n",
      " |  If the algorithm stops before fully converging (because of ``tol`` or\n",
      " |  ``max_iter``), ``labels_`` and ``cluster_centers_`` will not be consistent,\n",
      " |  i.e. the ``cluster_centers_`` will not be the means of the points in each\n",
      " |  cluster. Also, the estimator will reassign ``labels_`` after the last\n",
      " |  iteration to make ``labels_`` consistent with ``predict`` on the training\n",
      " |  set.\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |\n",
      " |  >>> from sklearn.cluster import KMeans\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.array([[1, 2], [1, 4], [1, 0],\n",
      " |  ...               [10, 2], [10, 4], [10, 0]])\n",
      " |  >>> kmeans = KMeans(n_clusters=2, random_state=0, n_init=\"auto\").fit(X)\n",
      " |  >>> kmeans.labels_\n",
      " |  array([1, 1, 1, 0, 0, 0], dtype=int32)\n",
      " |  >>> kmeans.predict([[0, 0], [12, 3]])\n",
      " |  array([1, 0], dtype=int32)\n",
      " |  >>> kmeans.cluster_centers_\n",
      " |  array([[10.,  2.],\n",
      " |         [ 1.,  2.]])\n",
      " |\n",
      " |  For a more detailed example of K-Means using the iris dataset see\n",
      " |  :ref:`sphx_glr_auto_examples_cluster_plot_cluster_iris.py`.\n",
      " |\n",
      " |  For examples of common problems with K-Means and how to address them see\n",
      " |  :ref:`sphx_glr_auto_examples_cluster_plot_kmeans_assumptions.py`.\n",
      " |\n",
      " |  For an example of how to use K-Means to perform color quantization see\n",
      " |  :ref:`sphx_glr_auto_examples_cluster_plot_color_quantization.py`.\n",
      " |\n",
      " |  For a demonstration of how K-Means can be used to cluster text documents see\n",
      " |  :ref:`sphx_glr_auto_examples_text_plot_document_clustering.py`.\n",
      " |\n",
      " |  For a comparison between K-Means and MiniBatchKMeans refer to example\n",
      " |  :ref:`sphx_glr_auto_examples_cluster_plot_mini_batch_kmeans.py`.\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      KMeans\n",
      " |      _BaseKMeans\n",
      " |      sklearn.base.ClassNamePrefixFeaturesOutMixin\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.utils._set_output._SetOutputMixin\n",
      " |      sklearn.base.ClusterMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, n_clusters=8, *, init='k-means++', n_init='auto', max_iter=300, tol=0.0001, verbose=0, random_state=None, copy_x=True, algorithm='lloyd')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  fit(self, X, y=None, sample_weight=None)\n",
      " |      Compute k-means clustering.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training instances to cluster. It must be noted that the data\n",
      " |          will be converted to C ordering, which will cause a memory\n",
      " |          copy if the given data is not C-contiguous.\n",
      " |          If a sparse matrix is passed, a copy will be made if it's not in\n",
      " |          CSR format.\n",
      " |\n",
      " |      y : Ignored\n",
      " |          Not used, present here for API consistency by convention.\n",
      " |\n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight. `sample_weight` is not used during\n",
      " |          initialization if `init` is a callable or a user provided array.\n",
      " |\n",
      " |          .. versionadded:: 0.20\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |\n",
      " |  set_fit_request(self: sklearn.cluster._kmeans.KMeans, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.cluster._kmeans.KMeans from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |\n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |\n",
      " |      The options for each parameter are:\n",
      " |\n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |\n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |\n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |\n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |\n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |\n",
      " |      .. versionadded:: 1.3\n",
      " |\n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |\n",
      " |  set_score_request(self: sklearn.cluster._kmeans.KMeans, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.cluster._kmeans.KMeans from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      " |      Request metadata passed to the ``score`` method.\n",
      " |\n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |\n",
      " |      The options for each parameter are:\n",
      " |\n",
      " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      " |\n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      " |\n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |\n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |\n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |\n",
      " |      .. versionadded:: 1.3\n",
      " |\n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _BaseKMeans:\n",
      " |\n",
      " |  fit_predict(self, X, y=None, sample_weight=None)\n",
      " |      Compute cluster centers and predict cluster index for each sample.\n",
      " |\n",
      " |      Convenience method; equivalent to calling fit(X) followed by\n",
      " |      predict(X).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          New data to transform.\n",
      " |\n",
      " |      y : Ignored\n",
      " |          Not used, present here for API consistency by convention.\n",
      " |\n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : ndarray of shape (n_samples,)\n",
      " |          Index of the cluster each sample belongs to.\n",
      " |\n",
      " |  fit_transform(self, X, y=None, sample_weight=None)\n",
      " |      Compute clustering and transform X to cluster-distance space.\n",
      " |\n",
      " |      Equivalent to fit(X).transform(X), but more efficiently implemented.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          New data to transform.\n",
      " |\n",
      " |      y : Ignored\n",
      " |          Not used, present here for API consistency by convention.\n",
      " |\n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray of shape (n_samples, n_clusters)\n",
      " |          X transformed in the new space.\n",
      " |\n",
      " |  predict(self, X)\n",
      " |      Predict the closest cluster each sample in X belongs to.\n",
      " |\n",
      " |      In the vector quantization literature, `cluster_centers_` is called\n",
      " |      the code book and each value returned by `predict` is the index of\n",
      " |      the closest code in the code book.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          New data to predict.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : ndarray of shape (n_samples,)\n",
      " |          Index of the cluster each sample belongs to.\n",
      " |\n",
      " |  score(self, X, y=None, sample_weight=None)\n",
      " |      Opposite of the value of X on the K-means objective.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          New data.\n",
      " |\n",
      " |      y : Ignored\n",
      " |          Not used, present here for API consistency by convention.\n",
      " |\n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Opposite of the value of X on the K-means objective.\n",
      " |\n",
      " |  transform(self, X)\n",
      " |      Transform X to a cluster-distance space.\n",
      " |\n",
      " |      In the new space, each dimension is the distance to the cluster\n",
      " |      centers. Note that even if X is sparse, the array returned by\n",
      " |      `transform` will typically be dense.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          New data to transform.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray of shape (n_samples, n_clusters)\n",
      " |          X transformed in the new space.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassNamePrefixFeaturesOutMixin:\n",
      " |\n",
      " |  get_feature_names_out(self, input_features=None)\n",
      " |      Get output feature names for transformation.\n",
      " |\n",
      " |      The feature names out will prefixed by the lowercased class name. For\n",
      " |      example, if the transformer outputs 3 features, then the feature names\n",
      " |      out are: `[\"class_name0\", \"class_name1\", \"class_name2\"]`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      input_features : array-like of str or None, default=None\n",
      " |          Only used to validate feature names with the names seen in `fit`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_names_out : ndarray of str objects\n",
      " |          Transformed feature names.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassNamePrefixFeaturesOutMixin:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |\n",
      " |  set_output(self, *, transform=None)\n",
      " |      Set output container.\n",
      " |\n",
      " |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      " |      for an example on how to use the API.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      " |          Configure output of `transform` and `fit_transform`.\n",
      " |\n",
      " |          - `\"default\"`: Default output format of a transformer\n",
      " |          - `\"pandas\"`: DataFrame output\n",
      " |          - `\"polars\"`: Polars output\n",
      " |          - `None`: Transform configuration is unchanged\n",
      " |\n",
      " |          .. versionadded:: 1.4\n",
      " |              `\"polars\"` option was added.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |\n",
      " |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      " |      This method is called when a class is subclassed.\n",
      " |\n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |\n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |\n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |\n",
      " |  __setstate__(self, state)\n",
      " |\n",
      " |  __sklearn_clone__(self)\n",
      " |\n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |\n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |\n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |\n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |\n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(KMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd94d93a-87c6-4c9d-b97e-4cc5df9e2aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2599.3873849123092"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters = 2, init='k-means++')\n",
    "\n",
    "kmeans.fit(data_scaled)\n",
    "\n",
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db6e8122-d0d5-49e3-bb3a-f8561938e48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wcss = []\n",
    "\n",
    "for cluster in range(1, 21):\n",
    "    kmeans = KMeans(n_clusters = cluster, init='k-means++')\n",
    "    kmeans.fit(data_scaled)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize = (6, 3))\n",
    "plt.plot(range(1, 21), wcss, marker = 'o')\n",
    "plt.title('The Elbow Curve')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a49c0454-45e7-4228-9fae-79613a9cde4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>0.052933</td>\n",
       "      <td>0.523568</td>\n",
       "      <td>-0.041115</td>\n",
       "      <td>-0.589367</td>\n",
       "      <td>-0.043569</td>\n",
       "      <td>-0.066339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>-0.391302</td>\n",
       "      <td>0.544458</td>\n",
       "      <td>0.170318</td>\n",
       "      <td>-0.270136</td>\n",
       "      <td>0.086407</td>\n",
       "      <td>0.089151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>-0.447029</td>\n",
       "      <td>0.408538</td>\n",
       "      <td>-0.028157</td>\n",
       "      <td>-0.137536</td>\n",
       "      <td>0.133232</td>\n",
       "      <td>2.243293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.690297</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>0.100111</td>\n",
       "      <td>-0.624020</td>\n",
       "      <td>-0.392977</td>\n",
       "      <td>0.687144</td>\n",
       "      <td>-0.498588</td>\n",
       "      <td>0.093411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>0.840239</td>\n",
       "      <td>-0.052396</td>\n",
       "      <td>-0.079356</td>\n",
       "      <td>0.173859</td>\n",
       "      <td>-0.231918</td>\n",
       "      <td>1.299347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.448652  0.590668  0.052933  0.523568 -0.041115 -0.589367 -0.043569   \n",
       "1  1.448652  0.590668 -0.391302  0.544458  0.170318 -0.270136  0.086407   \n",
       "2  1.448652  0.590668 -0.447029  0.408538 -0.028157 -0.137536  0.133232   \n",
       "3 -0.690297  0.590668  0.100111 -0.624020 -0.392977  0.687144 -0.498588   \n",
       "4  1.448652  0.590668  0.840239 -0.052396 -0.079356  0.173859 -0.231918   \n",
       "\n",
       "          7  \n",
       "0 -0.066339  \n",
       "1  0.089151  \n",
       "2  2.243293  \n",
       "3  0.093411  \n",
       "4  1.299347  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model with the 6 clusters\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters = 6, init = 'k-means++')\n",
    "kmeans.fit(data_scaled)\n",
    "pred = kmeans.predict(data_scaled)\n",
    "\n",
    "df = pd.DataFrame(data_scaled)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d09d06f-16ba-43c1-9b3a-5988bb4fd926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>0.052933</td>\n",
       "      <td>0.523568</td>\n",
       "      <td>-0.041115</td>\n",
       "      <td>-0.589367</td>\n",
       "      <td>-0.043569</td>\n",
       "      <td>-0.066339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>-0.391302</td>\n",
       "      <td>0.544458</td>\n",
       "      <td>0.170318</td>\n",
       "      <td>-0.270136</td>\n",
       "      <td>0.086407</td>\n",
       "      <td>0.089151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>-0.447029</td>\n",
       "      <td>0.408538</td>\n",
       "      <td>-0.028157</td>\n",
       "      <td>-0.137536</td>\n",
       "      <td>0.133232</td>\n",
       "      <td>2.243293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.690297</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>0.100111</td>\n",
       "      <td>-0.624020</td>\n",
       "      <td>-0.392977</td>\n",
       "      <td>0.687144</td>\n",
       "      <td>-0.498588</td>\n",
       "      <td>0.093411</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>0.840239</td>\n",
       "      <td>-0.052396</td>\n",
       "      <td>-0.079356</td>\n",
       "      <td>0.173859</td>\n",
       "      <td>-0.231918</td>\n",
       "      <td>1.299347</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.448652  0.590668  0.052933  0.523568 -0.041115 -0.589367 -0.043569   \n",
       "1  1.448652  0.590668 -0.391302  0.544458  0.170318 -0.270136  0.086407   \n",
       "2  1.448652  0.590668 -0.447029  0.408538 -0.028157 -0.137536  0.133232   \n",
       "3 -0.690297  0.590668  0.100111 -0.624020 -0.392977  0.687144 -0.498588   \n",
       "4  1.448652  0.590668  0.840239 -0.052396 -0.079356  0.173859 -0.231918   \n",
       "\n",
       "          7  cluster  \n",
       "0 -0.066339        0  \n",
       "1  0.089151        0  \n",
       "2  2.243293        0  \n",
       "3  0.093411        1  \n",
       "4  1.299347        0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cluster'] = pred\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f544def6-b67b-4b86-a1c7-28dec540ce3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>-0.690297</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>1.401312</td>\n",
       "      <td>0.848446</td>\n",
       "      <td>0.850760</td>\n",
       "      <td>2.075222</td>\n",
       "      <td>-0.566831</td>\n",
       "      <td>0.241091</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>-0.690297</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>2.155293</td>\n",
       "      <td>-0.592142</td>\n",
       "      <td>-0.757165</td>\n",
       "      <td>0.296561</td>\n",
       "      <td>-0.585519</td>\n",
       "      <td>0.291501</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>0.200326</td>\n",
       "      <td>1.314671</td>\n",
       "      <td>2.348386</td>\n",
       "      <td>-0.543380</td>\n",
       "      <td>2.511218</td>\n",
       "      <td>0.121456</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.690297</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>-0.135384</td>\n",
       "      <td>-0.517536</td>\n",
       "      <td>-0.602514</td>\n",
       "      <td>-0.419441</td>\n",
       "      <td>-0.569770</td>\n",
       "      <td>0.213046</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>-0.690297</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>-0.729307</td>\n",
       "      <td>-0.555924</td>\n",
       "      <td>-0.573227</td>\n",
       "      <td>-0.620094</td>\n",
       "      <td>-0.504888</td>\n",
       "      <td>-0.522869</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "435 -0.690297  0.590668  1.401312  0.848446  0.850760  2.075222 -0.566831   \n",
       "436 -0.690297  0.590668  2.155293 -0.592142 -0.757165  0.296561 -0.585519   \n",
       "437  1.448652  0.590668  0.200326  1.314671  2.348386 -0.543380  2.511218   \n",
       "438 -0.690297  0.590668 -0.135384 -0.517536 -0.602514 -0.419441 -0.569770   \n",
       "439 -0.690297  0.590668 -0.729307 -0.555924 -0.573227 -0.620094 -0.504888   \n",
       "\n",
       "            7  cluster  \n",
       "435  0.241091        3  \n",
       "436  0.291501        3  \n",
       "437  0.121456        0  \n",
       "438  0.213046        1  \n",
       "439 -0.522869        1  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db89950a-deb5-4abf-83b1-474273f1a831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>0.052933</td>\n",
       "      <td>0.523568</td>\n",
       "      <td>-0.041115</td>\n",
       "      <td>-0.589367</td>\n",
       "      <td>-0.043569</td>\n",
       "      <td>-0.066339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>-0.391302</td>\n",
       "      <td>0.544458</td>\n",
       "      <td>0.170318</td>\n",
       "      <td>-0.270136</td>\n",
       "      <td>0.086407</td>\n",
       "      <td>0.089151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>-0.447029</td>\n",
       "      <td>0.408538</td>\n",
       "      <td>-0.028157</td>\n",
       "      <td>-0.137536</td>\n",
       "      <td>0.133232</td>\n",
       "      <td>2.243293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.690297</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>0.100111</td>\n",
       "      <td>-0.624020</td>\n",
       "      <td>-0.392977</td>\n",
       "      <td>0.687144</td>\n",
       "      <td>-0.498588</td>\n",
       "      <td>0.093411</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>0.840239</td>\n",
       "      <td>-0.052396</td>\n",
       "      <td>-0.079356</td>\n",
       "      <td>0.173859</td>\n",
       "      <td>-0.231918</td>\n",
       "      <td>1.299347</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>-0.204806</td>\n",
       "      <td>0.334067</td>\n",
       "      <td>-0.297637</td>\n",
       "      <td>-0.496155</td>\n",
       "      <td>-0.228138</td>\n",
       "      <td>-0.026224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>0.009950</td>\n",
       "      <td>-0.352316</td>\n",
       "      <td>-0.102849</td>\n",
       "      <td>-0.534512</td>\n",
       "      <td>0.054280</td>\n",
       "      <td>-0.347854</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>-0.349981</td>\n",
       "      <td>-0.113981</td>\n",
       "      <td>0.155359</td>\n",
       "      <td>-0.289315</td>\n",
       "      <td>0.092286</td>\n",
       "      <td>0.369601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.690297</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>-0.477901</td>\n",
       "      <td>-0.291409</td>\n",
       "      <td>-0.185336</td>\n",
       "      <td>-0.545854</td>\n",
       "      <td>-0.244726</td>\n",
       "      <td>-0.275079</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>-0.474497</td>\n",
       "      <td>0.718495</td>\n",
       "      <td>1.151423</td>\n",
       "      <td>-0.394488</td>\n",
       "      <td>0.954031</td>\n",
       "      <td>0.203461</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>-0.683474</td>\n",
       "      <td>-0.053346</td>\n",
       "      <td>0.529133</td>\n",
       "      <td>0.273876</td>\n",
       "      <td>0.649984</td>\n",
       "      <td>0.077791</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>0.090692</td>\n",
       "      <td>-0.633787</td>\n",
       "      <td>-0.361162</td>\n",
       "      <td>-0.340664</td>\n",
       "      <td>-0.489769</td>\n",
       "      <td>-0.364894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>1.560499</td>\n",
       "      <td>0.884800</td>\n",
       "      <td>0.400925</td>\n",
       "      <td>-0.574313</td>\n",
       "      <td>0.209873</td>\n",
       "      <td>0.499176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>0.729576</td>\n",
       "      <td>0.055851</td>\n",
       "      <td>0.740672</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.803267</td>\n",
       "      <td>-0.327619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>1.001564</td>\n",
       "      <td>0.497659</td>\n",
       "      <td>0.436111</td>\n",
       "      <td>-0.572869</td>\n",
       "      <td>0.457016</td>\n",
       "      <td>0.228311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.690297</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>-0.138313</td>\n",
       "      <td>-0.635143</td>\n",
       "      <td>-0.435116</td>\n",
       "      <td>-0.551629</td>\n",
       "      <td>-0.402629</td>\n",
       "      <td>-0.395069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>-0.869179</td>\n",
       "      <td>0.409623</td>\n",
       "      <td>0.439272</td>\n",
       "      <td>-0.605865</td>\n",
       "      <td>0.341529</td>\n",
       "      <td>-0.157929</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.690297</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>-0.484788</td>\n",
       "      <td>0.048933</td>\n",
       "      <td>-0.528665</td>\n",
       "      <td>-0.460479</td>\n",
       "      <td>-0.527355</td>\n",
       "      <td>1.048362</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.448652</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>0.522499</td>\n",
       "      <td>0.071993</td>\n",
       "      <td>0.226258</td>\n",
       "      <td>-0.178780</td>\n",
       "      <td>-0.024041</td>\n",
       "      <td>0.587926</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.690297</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>-0.334071</td>\n",
       "      <td>-0.447812</td>\n",
       "      <td>0.159362</td>\n",
       "      <td>-0.495536</td>\n",
       "      <td>-0.076325</td>\n",
       "      <td>-0.363474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0   1.448652  0.590668  0.052933  0.523568 -0.041115 -0.589367 -0.043569   \n",
       "1   1.448652  0.590668 -0.391302  0.544458  0.170318 -0.270136  0.086407   \n",
       "2   1.448652  0.590668 -0.447029  0.408538 -0.028157 -0.137536  0.133232   \n",
       "3  -0.690297  0.590668  0.100111 -0.624020 -0.392977  0.687144 -0.498588   \n",
       "4   1.448652  0.590668  0.840239 -0.052396 -0.079356  0.173859 -0.231918   \n",
       "5   1.448652  0.590668 -0.204806  0.334067 -0.297637 -0.496155 -0.228138   \n",
       "6   1.448652  0.590668  0.009950 -0.352316 -0.102849 -0.534512  0.054280   \n",
       "7   1.448652  0.590668 -0.349981 -0.113981  0.155359 -0.289315  0.092286   \n",
       "8  -0.690297  0.590668 -0.477901 -0.291409 -0.185336 -0.545854 -0.244726   \n",
       "9   1.448652  0.590668 -0.474497  0.718495  1.151423 -0.394488  0.954031   \n",
       "10  1.448652  0.590668 -0.683474 -0.053346  0.529133  0.273876  0.649984   \n",
       "11  1.448652  0.590668  0.090692 -0.633787 -0.361162 -0.340664 -0.489769   \n",
       "12  1.448652  0.590668  1.560499  0.884800  0.400925 -0.574313  0.209873   \n",
       "13  1.448652  0.590668  0.729576  0.055851  0.740672  0.004757  0.803267   \n",
       "14  1.448652  0.590668  1.001564  0.497659  0.436111 -0.572869  0.457016   \n",
       "15 -0.690297  0.590668 -0.138313 -0.635143 -0.435116 -0.551629 -0.402629   \n",
       "16  1.448652  0.590668 -0.869179  0.409623  0.439272 -0.605865  0.341529   \n",
       "17 -0.690297  0.590668 -0.484788  0.048933 -0.528665 -0.460479 -0.527355   \n",
       "18  1.448652  0.590668  0.522499  0.071993  0.226258 -0.178780 -0.024041   \n",
       "19 -0.690297  0.590668 -0.334071 -0.447812  0.159362 -0.495536 -0.076325   \n",
       "\n",
       "           7  cluster  \n",
       "0  -0.066339        0  \n",
       "1   0.089151        0  \n",
       "2   2.243293        0  \n",
       "3   0.093411        1  \n",
       "4   1.299347        0  \n",
       "5  -0.026224        0  \n",
       "6  -0.347854        0  \n",
       "7   0.369601        0  \n",
       "8  -0.275079        1  \n",
       "9   0.203461        0  \n",
       "10  0.077791        0  \n",
       "11 -0.364894        0  \n",
       "12  0.499176        0  \n",
       "13 -0.327619        0  \n",
       "14  0.228311        0  \n",
       "15 -0.395069        1  \n",
       "16 -0.157929        0  \n",
       "17  1.048362        1  \n",
       "18  0.587926        0  \n",
       "19 -0.363474        1  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a73fa09-7ba2-4b12-a702-9d03b8536def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "1    252\n",
       "0    129\n",
       "3     46\n",
       "2     10\n",
       "4      2\n",
       "5      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d92696-4549-44e9-9fa9-530b79758054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to take input, standardize it, and predict the cluster\n",
    "def get_cluster_prediction():\n",
    "    # Collecting user for each feature\n",
    "    Channel = int(input(\"Enter Channel (e.g., 1, 2): \"))\n",
    "    Region = int(input(\"Enter Region (e.g., 1, 2, 3 ): \"))\n",
    "    Fresh = float(input(\"Enter annual spending on Fresh products: \"))\n",
    "    Milk = float(input(\"Enter annual spending on Milk: \"))\n",
    "    Grocery = float(input(\"Enter annual spending on Grocery: \"))\n",
    "    Frozen = float(input(\"Enter annual spending on Frozen products: \"))\n",
    "    Detergents_Paper = float(input(\"Enter annual spending on Detergents_Paper: \"))\n",
    "    Delicassen = float(input(\"Enter annual spending on Delicassen: \"))\n",
    "    # Create a data point with the input values\n",
    "    user_data = np.array([[Channel, Region, Fresh, Milk, Grocery, Frozen, Detergents_Paper, Delicassen]])\n",
    "    # Standardize the user input using the already fitted scaler\n",
    "    user_data_scaled = scaler.transform(user_data)\n",
    "    # Predict the cluster using the clustering model\n",
    "    cluster = kmeans.predict(user_data_scaled)\n",
    "    # Output the predicted cluster \n",
    "    print(f\"The customer belongs to cluster: {cluster[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ddcc40-461a-470d-93ce-ba300d453b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Channel (e.g., 1, 2):  1\n",
      "Enter Region (e.g., 1, 2, 3 ):  3\n",
      "Enter annual spending on Fresh products:  25456\n",
      "Enter annual spending on Milk:  9000\n",
      "Enter annual spending on Grocery:  2500\n"
     ]
    }
   ],
   "source": [
    "get_cluster_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f29d664-73fa-46e0-9ba3-f2e9a69e98f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
